{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "mount_file_id": "1QDdSvwBwYvQpGZEtGswvQu0L6TTCwg7r",
   "authorship_tag": "ABX9TyMWfaRRhwz95r5JZs7KSQqN"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiOhUoday74M",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722667440486,
     "user_tz": -120,
     "elapsed": 5101,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "8233af09-dfb4-49ad-b629-1afdcca5b448",
    "ExecuteTime": {
     "end_time": "2024-08-03T14:43:45.066840Z",
     "start_time": "2024-08-03T14:43:43.738195Z"
    }
   },
   "source": "# Runs in Google Colab",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "print(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7BATJJMzXJ6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722667458255,
     "user_tz": -120,
     "elapsed": 17774,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "3537557b-779f-4b2d-dd00-68dfb780fc40"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Vanilla GAN\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def make_generator_network(\n",
    "    input_size=20,\n",
    "    num_hidden_layers=1,\n",
    "    num_hidden_units=100,\n",
    "    num_output_units=784\n",
    "):\n",
    "    model = nn.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "      model.add_module(f'fc_g{i}', nn.Linear(input_size, num_hidden_units))\n",
    "      model.add_module(f'relu_g{i}', nn.LeakyReLU())\n",
    "      input_size = num_hidden_units\n",
    "\n",
    "    model.add_module(\n",
    "        f'fc_g{num_hidden_layers}',\n",
    "        nn.Linear(input_size, num_output_units)\n",
    "    )\n",
    "    model.add_module('tanh_g', nn.Tanh())\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_discriminator_network(\n",
    "    input_size=20,\n",
    "    num_hidden_layers=1,\n",
    "    num_hidden_units=100,\n",
    "    num_output_units=1\n",
    "):\n",
    "    model = nn.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "      model.add_module(\n",
    "          f'fc_d{i}',\n",
    "          nn.Linear(input_size, num_hidden_units, bias=False)\n",
    "      )\n",
    "      model.add_module(f'relu_d{i}', nn.LeakyReLU())\n",
    "      model.add_module('dropout', nn.Dropout(p=0.5))\n",
    "      input_size = num_hidden_units\n",
    "\n",
    "    model.add_module(\n",
    "        f'fc_d{num_hidden_layers}',\n",
    "        nn.Linear(input_size, num_output_units)\n",
    "    )\n",
    "    model.add_module('sigmoid', nn.Sigmoid())\n",
    "    return model"
   ],
   "metadata": {
    "id": "XPlUqC-9z23R",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722667458255,
     "user_tz": -120,
     "elapsed": 12,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "image_size = (28, 28)\n",
    "z_size = 20\n",
    "gen_hidden_layers = 1\n",
    "gen_hidden_size = 100\n",
    "disc_hidden_layers = 1\n",
    "disc_hidden_size = 100\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "gen_model = make_generator_network(\n",
    "    input_size=z_size,\n",
    "    num_hidden_layers=gen_hidden_layers,\n",
    "    num_hidden_units=gen_hidden_size,\n",
    "    num_output_units=np.prod(image_size)\n",
    ")\n",
    "print(gen_model)\n",
    "\n",
    "disc_model = make_discriminator_network(\n",
    "    input_size=np.prod(image_size),\n",
    "    num_hidden_layers=disc_hidden_layers,\n",
    "    num_hidden_units=disc_hidden_size\n",
    ")\n",
    "print(disc_model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GVrLavU2jPE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722667458255,
     "user_tz": -120,
     "elapsed": 11,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "cdd457fd-0ffa-40ce-948d-5b91dc1d4e58"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Scale images from [0, 255] to [-1, 1]\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "image_path = './'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "mnist_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "example, label = next(iter(mnist_dataset))\n",
    "print(f'Min: {example.min()} Max: {example.max()}')\n",
    "print(example.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1BgRvJF3cs2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722667464939,
     "user_tz": -120,
     "elapsed": 6694,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "02a1ff72-2aee-4c5e-a142-31b5c289c8d4"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_noise(batch_size, z_size, mode_z):\n",
    "  if mode_z == 'uniform':\n",
    "    input_z = torch.rand(batch_size, z_size) * 2 - 1\n",
    "  elif mode_z == 'normal':\n",
    "    input_z = torch.randn(batch_size, z_size)\n",
    "  return input_z"
   ],
   "metadata": {
    "id": "TkmqWvbu36F3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722667464939,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(mnist_dataset, batch_size, shuffle=False)\n",
    "input_real, label = next(iter(dataloader))\n",
    "input_real = input_real.view(batch_size, -1)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "mode_z = 'uniform'\n",
    "input_z = create_noise(batch_size, z_size, mode_z)\n",
    "print('input-z -- shape:', input_z.shape)\n",
    "print('input-real -- shape:', input_real.shape)\n",
    "\n",
    "g_output = gen_model(input_z)\n",
    "print('Output of G -- shape:', g_output.shape)\n",
    "\n",
    "d_proba_real = disc_model(input_real)\n",
    "d_proba_fake = disc_model(g_output)\n",
    "print('Disc. (real) -- shape:', d_proba_real.shape)\n",
    "print('Disc. (fake) -- shape:', d_proba_fake.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZM93Dh94QVy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722667464940,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "044ed599-0093-4919-9b57-0d0dbe0a7c53"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training the GAN model\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "g_labels_real = torch.ones_like(d_proba_fake)\n",
    "g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
    "print(f'Generator Loss: {g_loss:.4f}')\n",
    "\n",
    "d_labels_real = torch.ones_like(d_proba_real)\n",
    "d_labels_fake = torch.zeros_like(d_proba_fake)\n",
    "d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
    "d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
    "print(f'Discriminator Losses: Real {d_loss_real:.4f} Fake {d_loss_fake:.4f}')"
   ],
   "metadata": {
    "id": "63pqjyyr469-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722667535574,
     "user_tz": -120,
     "elapsed": 297,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "5400d572-d588-4e5c-9888-a041f2ebbcbc"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "mnist_dl = DataLoader(\n",
    "    mnist_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "gen_model = make_generator_network(\n",
    "    input_size=z_size,\n",
    "    num_hidden_layers=gen_hidden_layers,\n",
    "    num_hidden_units=gen_hidden_size,\n",
    "    num_output_units=np.prod(image_size)\n",
    ").to(device)\n",
    "disc_model = make_discriminator_network(\n",
    "    input_size=np.prod(image_size),\n",
    "    num_hidden_layers=disc_hidden_layers,\n",
    "    num_hidden_units=disc_hidden_size\n",
    ").to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "g_optimizer = torch.optim.Adam(gen_model.parameters())\n",
    "d_optimizer = torch.optim.Adam(disc_model.parameters())"
   ],
   "metadata": {
    "id": "YhvGEd8b-nmm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722667785583,
     "user_tz": -120,
     "elapsed": 299,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def d_train(x):\n",
    "  disc_model.zero_grad()\n",
    "\n",
    "  # Train with a real batch\n",
    "  batch_size = x.size(0)\n",
    "  x = x.view(batch_size, -1).to(device)\n",
    "  d_labels_real = torch.ones(batch_size, 1, device=device)\n",
    "  d_proba_real = disc_model(x)\n",
    "  d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
    "\n",
    "# Train with a fake batch\n",
    "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "  g_output = gen_model(input_z)\n",
    "  d_proba_fake = disc_model(g_output)\n",
    "  d_labels_fake = torch.zeros(batch_size, 1, device=device)\n",
    "  d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
    "\n",
    "  d_loss = d_loss_real + d_loss_fake\n",
    "  d_loss.backward()\n",
    "  d_optimizer.step()\n",
    "  return (\n",
    "      d_loss.data.item(),\n",
    "      d_proba_real.detach(),\n",
    "      d_proba_fake.detach()\n",
    "  )\n",
    "\n",
    "\n",
    "def g_train(x):\n",
    "  gen_model.zero_grad()\n",
    "  batch_size = x.size(0)\n",
    "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "  g_labels_real = torch.ones(batch_size, 1, device=device)\n",
    "\n",
    "  g_output = gen_model(input_z)\n",
    "  d_proba_fake = disc_model(g_output)\n",
    "  g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
    "\n",
    "  g_loss.backward()\n",
    "  g_optimizer.step()\n",
    "  return g_loss.data.item()"
   ],
   "metadata": {
    "id": "8CkUPB6s__XU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722668137247,
     "user_tz": -120,
     "elapsed": 300,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "\n",
    "def create_samples(g_model, input_z):\n",
    "  g_output = g_model(input_z)\n",
    "  images = torch.reshape(g_output, (batch_size, *image_size))\n",
    "  return (images+1)/2.0\n",
    "\n",
    "\n",
    "epoch_samples = []\n",
    "all_d_losses = []\n",
    "all_g_losses = []\n",
    "all_d_real = []\n",
    "all_d_fake = []\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  d_losses, g_losses = [], []\n",
    "  d_vals_real, d_vals_fake = [], []\n",
    "  for i, (x, _) in enumerate(mnist_dl):\n",
    "    d_loss, d_proba_real, d_proba_fake = d_train(x)\n",
    "    d_losses.append(d_loss)\n",
    "    g_losses.append(g_train(x))\n",
    "    d_vals_real.append(d_proba_real.mean().cpu())\n",
    "    d_vals_fake.append(d_proba_fake.mean().cpu())\n",
    "\n",
    "  all_d_losses.append(torch.tensor(d_losses).mean())\n",
    "  all_g_losses.append(torch.tensor(g_losses).mean())\n",
    "  all_d_real.append(torch.tensor(d_vals_real).mean())\n",
    "  all_d_fake.append(torch.tensor(d_vals_fake).mean())\n",
    "\n",
    "  print(\n",
    "      f'Epoch {epoch:03d} | Avg Losses >>'\n",
    "      f' G/D {all_g_losses[-1]:.4f}/{all_d_losses[-1]:.4f}'\n",
    "      f' [D-Real: {all_d_real[-1]:.4f}'\n",
    "      f' D-Fake: {all_d_fake[-1]:.4f}]'\n",
    "  )\n",
    "  epoch_samples.append(create_samples(gen_model, fixed_z).detach().cpu().numpy())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTmg1ewDBbhu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722668776555,
     "user_tz": -120,
     "elapsed": 183039,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "842c11d1-e15b-41ab-d40f-dbe2c949c628"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "## Plotting the losses\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(all_g_losses, label='Generator loss')\n",
    "half_d_losses = [all_d_loss/2 for all_d_loss in all_d_losses]\n",
    "plt.plot(half_d_losses, label='Discriminator loss')\n",
    "plt.legend(fontsize=20)\n",
    "ax.set_xlabel('Iteration', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "\n",
    "## Plotting the outputs of the discriminator\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(all_d_real, label=r'Real: $D(\\mathbf{x})$')\n",
    "plt.plot(all_d_fake, label=r'Fake: $D(G(\\mathbf{z}))$')\n",
    "plt.legend(fontsize=20)\n",
    "ax.set_xlabel('Iteration', size=15)\n",
    "ax.set_ylabel('Discriminator output', size=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "KiPQOvPpDK_k",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722668792223,
     "user_tz": -120,
     "elapsed": 950,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "b1ef2c04-4b81-419f-f227-1ae29dacbe19"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "selected_epochs = [1, 2, 4, 10]\n",
    "fig = plt.figure(figsize=(10, 14))\n",
    "for i,e in enumerate(selected_epochs):\n",
    "  for j in range(5):\n",
    "    ax = fig.add_subplot(6, 5, i*5+j+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if j == 0:\n",
    "      ax.text(\n",
    "          -0.06, 0.5, f'Epoch {e}',\n",
    "          rotation=90, size=18, color='red',\n",
    "          horizontalalignment='right',\n",
    "          verticalalignment='center',\n",
    "          transform=ax.transAxes\n",
    "      )\n",
    "    image = epoch_samples[e-1][j]\n",
    "    ax.imshow(image, cmap='gray_r')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "id": "j5o0cU8-D5wO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722669084261,
     "user_tz": -120,
     "elapsed": 1302,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "c8a2ff2c-bcc8-485a-9507-e27c1ff9e24e"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Convolutional and Wasserstein GAN\n",
    "\n",
    "def make_generator_network(input_size, n_filters):\n",
    "  model = nn.Sequential(\n",
    "      nn.ConvTranspose2d(\n",
    "          input_size,\n",
    "          n_filters*4,\n",
    "          4, 1, 0,\n",
    "          bias=False\n",
    "      ),\n",
    "      nn.BatchNorm2d(n_filters*4),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.ConvTranspose2d(\n",
    "          n_filters*4,\n",
    "          n_filters*2,\n",
    "          3, 2, 1,\n",
    "          bias=False\n",
    "      ),\n",
    "      nn.BatchNorm2d(n_filters*2),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.ConvTranspose2d(\n",
    "          n_filters*2,\n",
    "          n_filters,\n",
    "          4, 2, 1,\n",
    "          bias=False\n",
    "      ),\n",
    "      nn.BatchNorm2d(n_filters),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.ConvTranspose2d(\n",
    "          n_filters,\n",
    "          1,\n",
    "          4, 2, 1,\n",
    "          bias=False\n",
    "      ),\n",
    "      nn.Tanh()\n",
    "  )\n",
    "  return model\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, n_filters):\n",
    "    super().__init__()\n",
    "    self.network = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            1,\n",
    "            n_filters,\n",
    "            4, 2, 1,\n",
    "            bias=False\n",
    "            ),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(\n",
    "            n_filters,\n",
    "            n_filters*2,\n",
    "            4, 2, 1,\n",
    "            bias=False\n",
    "        ),\n",
    "        nn.BatchNorm2d(n_filters*2),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(\n",
    "            n_filters*2,\n",
    "            n_filters*4,\n",
    "            3, 2, 1,\n",
    "            bias=False\n",
    "        ),\n",
    "        nn.BatchNorm2d(n_filters*4),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(\n",
    "            n_filters*4,\n",
    "            1,\n",
    "            4, 1, 0,\n",
    "            bias=False\n",
    "        ),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, input):\n",
    "    output = self.network(input)\n",
    "    return output.view(-1, 1).squeeze(0)"
   ],
   "metadata": {
    "id": "_AOc2JANEdNJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722671672862,
     "user_tz": -120,
     "elapsed": 279,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "z_size = 100\n",
    "image_size = (28, 28)\n",
    "n_filters = 32"
   ],
   "metadata": {
    "id": "eweQoujmN5r7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722671687618,
     "user_tz": -120,
     "elapsed": 278,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gen_model = make_generator_network(z_size, n_filters).to(device)\n",
    "print(gen_model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_K9ssUmO-Uy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722671705883,
     "user_tz": -120,
     "elapsed": 280,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "3c397a38-a721-41ac-b520-c9229eea9b3e"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "disc_model = Discriminator(n_filters).to(device)\n",
    "print(disc_model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8YiZe36PCv_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722671734029,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "d7e98425-b057-479b-fbbc-a294b422bc78"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "g_optimizer = torch.optim.Adam(gen_model.parameters(), 0.0003)\n",
    "d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.0002)"
   ],
   "metadata": {
    "id": "69K6l5rAPJn1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722671789203,
     "user_tz": -120,
     "elapsed": 294,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_noise(batch_size, z_size, mode_z):\n",
    "  if mode_z == 'uniform':\n",
    "    input_z = torch.rand(batch_size, z_size, 1, 1) * 2 - 1\n",
    "  elif mode_z == 'normal':\n",
    "    input_z = torch.randn(batch_size, z_size, 1, 1)\n",
    "  return input_z\n",
    "\n",
    "\n",
    "def d_train(x):\n",
    "  disc_model.zero_grad()\n",
    "\n",
    "  # Train with a real batch\n",
    "  batch_size = x.size(0)\n",
    "  x = x.to(device)\n",
    "  d_labels_real = torch.ones(batch_size, 1, device=device)\n",
    "  d_proba_real = disc_model(x)\n",
    "  d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
    "\n",
    "  # Train with a fake batch\n",
    "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "  g_output = gen_model(input_z)\n",
    "  d_proba_fake = disc_model(g_output)\n",
    "  d_labels_fake = torch.zeros(batch_size, 1, device=device)\n",
    "  d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
    "\n",
    "  d_loss = d_loss_real + d_loss_fake\n",
    "  d_loss.backward()\n",
    "  d_optimizer.step()\n",
    "  return (\n",
    "      d_loss.data.item(),\n",
    "      d_proba_real.detach(),\n",
    "      d_proba_fake.detach()\n",
    "  )"
   ],
   "metadata": {
    "id": "FtVb9hcFPXHh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722672299121,
     "user_tz": -120,
     "elapsed": 285,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "epoch_samples = []\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  gen_model.train()\n",
    "  for i, (x, _) in enumerate(mnist_dl):\n",
    "    d_loss, d_proba_real, d_proba_fake = d_train(x)\n",
    "    d_losses.append(d_loss)\n",
    "    g_losses.append(g_train(x))\n",
    "  print(\n",
    "      f'Epoch {epoch:03d} | Avg Losses >>'\n",
    "      f' G/D {torch.FloatTensor(g_losses).mean():.4f}'\n",
    "      f'/{torch.FloatTensor(d_losses).mean():.4f}'\n",
    "  )\n",
    "\n",
    "  gen_model.eval()\n",
    "  epoch_samples.append(\n",
    "      create_samples(\n",
    "          gen_model, fixed_z\n",
    "      ).detach().cpu().numpy()\n",
    "  )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfVpO_x-Qa4A",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722672579856,
     "user_tz": -120,
     "elapsed": 280245,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "295b13e2-fc80-401b-eeac-e44db99cc3af"
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "selected_epochs = [1, 2, 4, 10]\n",
    "fig = plt.figure(figsize=(10, 14))\n",
    "for i,e in enumerate(selected_epochs):\n",
    "  for j in range(5):\n",
    "    ax = fig.add_subplot(6, 5, i*5+j+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if j == 0:\n",
    "      ax.text(\n",
    "          -0.06, 0.5, f'Epoch {e}',\n",
    "          rotation=90, size=18, color='red',\n",
    "          horizontalalignment='right',\n",
    "          verticalalignment='center',\n",
    "          transform=ax.transAxes\n",
    "      )\n",
    "    image = epoch_samples[e-1][j]\n",
    "    ax.imshow(image, cmap='gray_r')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "id": "hDMFUDvlRBYB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722672614009,
     "user_tz": -120,
     "elapsed": 1183,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "6b0a343c-057d-4471-e388-50ae429340ab"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# WGAN-GP\n",
    "\n",
    "def make_generator_network_wgan(input_size, n_filters):\n",
    "  model = nn.Sequential(\n",
    "      nn.ConvTranspose2d(\n",
    "          input_size,\n",
    "          n_filters*4,\n",
    "          4, 1, 0,\n",
    "          bias=False\n",
    "      ),\n",
    "      nn.InstanceNorm2d(n_filters*4),\n",
    "      nn.LeakyReLU(0.2),\n",
    "\n",
    "      nn.ConvTranspose2d(\n",
    "          n_filters*4,\n",
    "          n_filters*2,\n",
    "          3, 2, 1,\n",
    "          bias=False\n",
    "      ),\n",
    "      nn.InstanceNorm2d(n_filters*2),\n",
    "      nn.LeakyReLU(0.2),\n",
    "\n",
    "      nn.ConvTranspose2d(\n",
    "          n_filters*2,\n",
    "          n_filters,\n",
    "          4, 2, 1,\n",
    "          bias=False\n",
    "      ),\n",
    "      nn.InstanceNorm2d(n_filters),\n",
    "      nn.LeakyReLU(0.2),\n",
    "\n",
    "      nn.ConvTranspose2d(\n",
    "          n_filters,\n",
    "          1,\n",
    "          4, 2, 1,\n",
    "          bias=False\n",
    "      ),\n",
    "      nn.Tanh()\n",
    "  )\n",
    "  return model\n",
    "\n",
    "\n",
    "class DiscriminatorWGAN(nn.Module):\n",
    "  def __init__(self, n_filters):\n",
    "    super().__init__()\n",
    "    self.network = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            1,\n",
    "            n_filters,\n",
    "            4, 2, 1,\n",
    "            bias=False\n",
    "        ),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(\n",
    "            n_filters,\n",
    "            n_filters*2,\n",
    "            4, 2, 1,\n",
    "            bias=False\n",
    "        ),\n",
    "        nn.InstanceNorm2d(n_filters*2),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(\n",
    "            n_filters*2,\n",
    "            n_filters*4,\n",
    "            3, 2, 1,\n",
    "            bias=False\n",
    "        ),\n",
    "        nn.InstanceNorm2d(n_filters*4),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(\n",
    "            n_filters*4,\n",
    "            1,\n",
    "            4, 1, 0,\n",
    "            bias=False\n",
    "        ),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, input):\n",
    "    output = self.network(input)\n",
    "    return output.view(-1, 1).squeeze(0)"
   ],
   "metadata": {
    "id": "Q1O-gvd1SU9T",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722675427983,
     "user_tz": -120,
     "elapsed": 300,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gen_model = make_generator_network_wgan(\n",
    "    z_size, n_filters\n",
    ").to(device)\n",
    "disc_model = DiscriminatorWGAN(n_filters).to(device)\n",
    "g_optimizer = torch.optim.Adam(gen_model.parameters(), 0.0002)\n",
    "d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.0002)\n",
    "\n",
    "\n",
    "from torch.autograd import grad as torch_grad\n",
    "\n",
    "def gradient_penalty(real_data, generated_data):\n",
    "  batch_size = real_data.size(0)\n",
    "  alpha = torch.rand(\n",
    "      real_data.shape[0],\n",
    "      1, 1, 1,\n",
    "      requires_grad=True,\n",
    "      device=device\n",
    "  )\n",
    "  interpolated = alpha * real_data + (1-alpha) * generated_data\n",
    "  proba_interpolated = disc_model(interpolated)\n",
    "  gradients = torch_grad(\n",
    "      outputs=proba_interpolated,\n",
    "      inputs=interpolated,\n",
    "      grad_outputs=torch.ones(proba_interpolated.size(), device=device),\n",
    "      create_graph=True,\n",
    "      retain_graph=True\n",
    "  )[0]\n",
    "  gradients = gradients.view(batch_size, -1)\n",
    "  gradients_norm = gradients.norm(2, dim=1)\n",
    "  return lambda_gp * ((gradients_norm-1)**2).mean()\n",
    "\n",
    "\n",
    "def d_train_wgan(x):\n",
    "  disc_model.zero_grad()\n",
    "\n",
    "  batch_size = x.size(0)\n",
    "  x = x.to(device)\n",
    "\n",
    "\n",
    "  d_real = disc_model(x)\n",
    "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "  g_output = gen_model(input_z)\n",
    "  d_generated = disc_model(g_output)\n",
    "  d_loss = d_generated.mean() - d_real.mean() + gradient_penalty(x.data, g_output.data)\n",
    "  d_loss.backward()\n",
    "  d_optimizer.step()\n",
    "  return d_loss.data.item()\n",
    "\n",
    "\n",
    "def g_train_wgan(x):\n",
    "  gen_model.zero_grad()\n",
    "\n",
    "  batch_size = x.size(0)\n",
    "  input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "  g_output = gen_model(input_z)\n",
    "\n",
    "  d_generated = disc_model(g_output)\n",
    "  g_loss = -d_generated.mean()\n",
    "\n",
    "  g_loss.backward()\n",
    "  g_optimizer.step()\n",
    "  return g_loss.data.item()"
   ],
   "metadata": {
    "id": "9TTUcMJ7atzP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722675617797,
     "user_tz": -120,
     "elapsed": 307,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epoch_samples_wgan = []\n",
    "lambda_gp = 10.0\n",
    "num_epochs = 10\n",
    "torch.manual_seed(1)\n",
    "critic_iterations = 5\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  gen_model.train()\n",
    "  d_losses, g_losses = [], []\n",
    "  for i, (x, _) in enumerate(mnist_dl):\n",
    "    for _ in range(critic_iterations):\n",
    "      d_loss = d_train_wgan(x)\n",
    "    d_losses.append(d_loss)\n",
    "    g_losses.append(g_train_wgan(x))\n",
    "\n",
    "  print(\n",
    "      f'Epoch {epoch:03d} | D Loss >>'\n",
    "      f' {torch.FloatTensor(d_losses).mean():.4f}'\n",
    "  )\n",
    "  gen_model.eval()\n",
    "  epoch_samples_wgan.append(\n",
    "      create_samples(\n",
    "        gen_model, fixed_z\n",
    "      ).detach().cpu().numpy()\n",
    "  )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cP07Q7cla1zO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722676332850,
     "user_tz": -120,
     "elapsed": 714630,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "19098bac-ea60-4b0c-b9ef-b88305a34be4"
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "selected_epochs = [1, 2, 4, 10]\n",
    "fig = plt.figure(figsize=(10, 14))\n",
    "for i,e in enumerate(selected_epochs):\n",
    "  for j in range(5):\n",
    "    ax = fig.add_subplot(6, 5, i*5+j+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if j == 0:\n",
    "      ax.text(\n",
    "          -0.06, 0.5, f'Epoch {e}',\n",
    "          rotation=90, size=18, color='red',\n",
    "          horizontalalignment='right',\n",
    "          verticalalignment='center',\n",
    "          transform=ax.transAxes\n",
    "      )\n",
    "    image = epoch_samples[e-1][j]\n",
    "    ax.imshow(image, cmap='gray_r')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "id": "7ASvQKYYdpSS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1722676402586,
     "user_tz": -120,
     "elapsed": 1898,
     "user": {
      "displayName": "Yevhenii Lavrinovych",
      "userId": "10763208162567727428"
     }
    },
    "outputId": "f9b2cac9-a14f-41e4-d032-36a4a5893ba7"
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Tv41Nmm2g9Cj"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
