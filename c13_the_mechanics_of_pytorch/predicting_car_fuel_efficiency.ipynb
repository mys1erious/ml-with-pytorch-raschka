{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T05:53:30.452272Z",
     "start_time": "2024-07-24T05:53:29.891267Z"
    }
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = [\n",
    "    'MPG',\n",
    "    'Cylinders',\n",
    "    'Displacement',\n",
    "    'Horsepower',\n",
    "    'Weight',\n",
    "    'Acceleration',\n",
    "    'Model Year',\n",
    "    'Origin',\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    url,\n",
    "    names=column_names,\n",
    "    na_values='?',\n",
    "    comment='\\t',\n",
    "    sep=' ',\n",
    "    skipinitialspace=True\n",
    ")\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "df_train, df_test = sklearn.model_selection.train_test_split(\n",
    "    df, train_size=0.8, random_state=1\n",
    ")\n",
    "train_stats = df_train.describe().transpose()\n",
    "\n",
    "# Numeric\n",
    "numeric_column_names = [\n",
    "    'Cylinders',\n",
    "    'Displacement',\n",
    "    'Horsepower',\n",
    "    'Weight',\n",
    "    'Acceleration',\n",
    "]\n",
    "\n",
    "df_train_norm, df_test_norm = df_train.copy(), df_test.copy()\n",
    "for col_name in numeric_column_names:\n",
    "    mean = train_stats.loc[col_name, 'mean']\n",
    "    std = train_stats.loc[col_name, 'std']\n",
    "    df_train_norm.loc[:, col_name] = (\n",
    "        df_train_norm.loc[:, col_name] - mean\n",
    "    ) / std\n",
    "    df_test_norm.loc[:, col_name] = (\n",
    "        df_test_norm.loc[:, col_name] - mean\n",
    "    ) / std\n",
    "    \n",
    "df_train_norm.tail()"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:53:30.461060Z",
     "start_time": "2024-07-24T05:53:30.453873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Buckets (ranges)\n",
    "\n",
    "import torch\n",
    "\n",
    "boundaries = torch.tensor([73, 76, 79])\n",
    "v = torch.tensor(df_train_norm['Model Year'].values)\n",
    "df_train_norm['Model Year Bucketed'] = torch.bucketize(\n",
    "    v, boundaries, right=True\n",
    ")\n",
    "v = torch.tensor(df_test_norm['Model Year'].values)\n",
    "df_test_norm['Model Year Bucketed'] = torch.bucketize(\n",
    "    v, boundaries, right=True\n",
    ")\n",
    "numeric_column_names.append('Model Year Bucketed')"
   ],
   "id": "560b877fe5e7cf00",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:53:31.977580Z",
     "start_time": "2024-07-24T05:53:31.971675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Categorical\n",
    "\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "total_origin = len(set(df_train_norm['Origin']))\n",
    "origin_encoded = one_hot(torch.from_numpy(\n",
    "    df_train_norm['Origin'].values % total_origin\n",
    "))\n",
    "x_train_numeric = torch.tensor(\n",
    "    df_train_norm[numeric_column_names].values\n",
    ")\n",
    "x_train = torch.cat([x_train_numeric, origin_encoded], 1).float()\n",
    "origin_encoded = one_hot(torch.from_numpy(\n",
    "    df_test_norm['Origin'].values\n",
    ") % total_origin)\n",
    "x_test_numeric = torch.tensor(\n",
    "    df_test_norm[numeric_column_names].values\n",
    ")\n",
    "x_test = torch.cat([x_test_numeric, origin_encoded], 1).float()\n",
    "y_train = torch.tensor(df_train_norm['MPG'].values).float()\n",
    "y_test = torch.tensor(df_test_norm['MPG'].values).float()"
   ],
   "id": "ceec67f5aa4044d0",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:53:32.306358Z",
     "start_time": "2024-07-24T05:53:32.298339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "batch_size = 8\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "hidden_units = [8, 4]\n",
    "input_size = x_train.shape[1]\n",
    "all_layers = []\n",
    "\n",
    "for hidden_unit in hidden_units:\n",
    "    layer = nn.Linear(input_size, hidden_unit)\n",
    "    all_layers.append(layer)\n",
    "    all_layers.append(nn.ReLU())\n",
    "    input_size = hidden_unit\n",
    "\n",
    "all_layers.append(nn.Linear(hidden_units[-1], 1))\n",
    "model = nn.Sequential(*all_layers)\n",
    "model"
   ],
   "id": "703183d5ce390d6d",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:53:37.491722Z",
     "start_time": "2024-07-24T05:53:32.755384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 200\n",
    "log_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_hist_train = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)[:, 0]\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_hist_train += loss.item()\n",
    "    if epoch % log_epochs == 0:\n",
    "        print(f'Epoch {epoch}Loss {loss_hist_train/len(train_dl):.4f}')"
   ],
   "id": "3e0f7c5dfc41e026",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T05:53:39.943253Z",
     "start_time": "2024-07-24T05:53:39.938675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(x_test.float())[:, 0]\n",
    "    loss = loss_fn(pred, y_test)\n",
    "    print(f'Test MSE: {loss.item():.4f}')\n",
    "    print(f'Test MAE: {nn.L1Loss()(pred, y_test).item():.4f}')"
   ],
   "id": "e489a9a1c95b4974",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "d6fbd644888dd0ea",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
