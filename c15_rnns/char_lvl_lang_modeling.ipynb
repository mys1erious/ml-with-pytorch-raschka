{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-28T10:20:50.950512Z",
     "start_time": "2024-07-28T10:20:50.843236Z"
    }
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with open('1268-0.txt', 'r', encoding='utf8') as fp:\n",
    "    text = fp.read()\n",
    "\n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find ('End of the Project Gutenberg')\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1112350\n",
      "Unique Characters: 80\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:23:07.405833Z",
     "start_time": "2024-07-28T10:23:07.327691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch: i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32\n",
    ")\n",
    "\n",
    "print('Text encoded shape:', text_encoded.shape)\n",
    "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
    "print(\n",
    "    text_encoded[15:21], '== Reverse ==>',\n",
    "    ''.join(char_array[text_encoded[15:21]])\n",
    ")"
   ],
   "id": "8d05d8a739606bfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape: (1112350,)\n",
      "THE MYSTERIOUS  == Encoding ==> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28] == Reverse ==> ISLAND\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:24:09.294592Z",
     "start_time": "2024-07-28T10:24:09.291874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for ex in text_encoded[:5]:\n",
    "    print('{} -> {}'.format(ex, char_array[ex]))"
   ],
   "id": "388927c9e8022213",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:29:44.656678Z",
     "start_time": "2024-07-28T10:29:37.063200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "text_chunks = [\n",
    "    text_encoded[i:i + chunk_size]\n",
    "    for i in range(len(text_encoded) - chunk_size + 1)\n",
    "]\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))\n",
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(\n",
    "        ' Input (x): ',\n",
    "        repr(''.join(char_array[seq]))\n",
    "    )\n",
    "    print(\n",
    "        'Target (y): ',\n",
    "        repr(''.join(char_array[target]))\n",
    "    )\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break"
   ],
   "id": "d265bd0d42d7dffb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x):  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "Target (y):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      " Input (x):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "Target (y):  'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by '\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_324284/2802846711.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:31:22.078356Z",
     "start_time": "2024-07-28T10:31:22.074497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(\n",
    "    seq_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ],
   "id": "a5cbfdd22d81a47d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:34:53.561625Z",
     "start_time": "2024-07-28T10:34:53.520943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(\n",
    "            embed_dim,\n",
    "            rnn_hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden, cell\n",
    "\n",
    "\n",
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
    "model"
   ],
   "id": "440b78691551302a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(80, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:40:48.936801Z",
     "start_time": "2024-07-28T10:39:11.436394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 200\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item() / seq_length\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')"
   ],
   "id": "8062076d55976d3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.5536\n",
      "Epoch 10 loss: 1.5974\n",
      "Epoch 20 loss: 1.5773\n",
      "Epoch 30 loss: 1.5042\n",
      "Epoch 40 loss: 1.5988\n",
      "Epoch 50 loss: 1.5669\n",
      "Epoch 60 loss: 1.5355\n",
      "Epoch 70 loss: 1.5525\n",
      "Epoch 80 loss: 1.5033\n",
      "Epoch 90 loss: 1.4675\n",
      "Epoch 100 loss: 1.5088\n",
      "Epoch 110 loss: 1.4264\n",
      "Epoch 120 loss: 1.4865\n",
      "Epoch 130 loss: 1.4706\n",
      "Epoch 140 loss: 1.5077\n",
      "Epoch 150 loss: 1.4634\n",
      "Epoch 160 loss: 1.4577\n",
      "Epoch 170 loss: 1.4491\n",
      "Epoch 180 loss: 1.4171\n",
      "Epoch 190 loss: 1.3909\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:41:43.623762Z",
     "start_time": "2024-07-28T10:41:43.615592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "torch.manual_seed(1)\n",
    "logits = torch.tensor([[1.0, 1.0, 1.0]])\n",
    "print(\n",
    "    'Probabilities:', \n",
    "    nn.functional.softmax(logits, dim=1).numpy()[0]\n",
    ")\n",
    "\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    "print(samples.numpy())"
   ],
   "id": "49926035e98f182e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:42:25.023989Z",
     "start_time": "2024-07-28T10:42:25.017992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1)\n",
    "logits = torch.tensor([[1.0, 1.0, 3.0]])\n",
    "print('Probabilities:', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    "print(samples.numpy())"
   ],
   "id": "9a004a6ef5caeb3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.10650698 0.10650698 0.78698605]\n",
      "[[0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:47:47.113056Z",
     "start_time": "2024-07-28T10:47:47.108719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample(\n",
    "        model, starting_str,\n",
    "        len_generated_text=500,\n",
    "        scale_factor=1.0\n",
    "):\n",
    "    encoded_input = torch.tensor(\n",
    "        [char2int[s] for s in starting_str]\n",
    "    )\n",
    "    encoded_input = torch.reshape(\n",
    "        encoded_input, (1, -1)\n",
    "    )\n",
    "    generated_str = starting_str\n",
    "    \n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(\n",
    "            encoded_input[:, c].view(1),\n",
    "            hidden, \n",
    "            cell\n",
    "        )\n",
    "    \n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(\n",
    "            last_char.view(1),\n",
    "            hidden,\n",
    "            cell\n",
    "        )\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(char_array[last_char])\n",
    "    \n",
    "    return generated_str"
   ],
   "id": "f27d9813fb67239f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:47:48.929076Z",
     "start_time": "2024-07-28T10:47:47.796034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1)\n",
    "print(sample(model, starting_str='The island'))"
   ],
   "id": "1242a996f35a3603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island.\n",
      "\n",
      "Still on the muttelling a ril unuse our\n",
      "to its claw opening, and canemst of the distance\n",
      "spy in aros helpo is prokes has bar Would be to as not hand on his yet spanions must too hall; in the Pacificed; on\n",
      "solped in again were during up I rasts, which mach, almost, and only to one of game, has seet; Pencroft creacially\n",
      "several could no thoughed of the dipies was our day othing time, but on the wreck over,\n",
      "togeting and way who with ratch of what discovicies! Nop were legned.\n",
      "\n",
      "They could not twe\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:49:49.165222Z",
     "start_time": "2024-07-28T10:49:49.161089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits = torch.tensor([[1.0, 1.0, 3.0]])\n",
    "print(\n",
    "    'Probabilities before scaling:',\n",
    "    nn.functional.softmax(logits, dim=1).numpy()[0]\n",
    ")\n",
    "\n",
    "print(\n",
    "    'Probabilities after scaling with 0.5:',\n",
    "    nn.functional.softmax(0.5 * logits, dim=1).numpy()[0]\n",
    ")\n",
    "\n",
    "print(\n",
    "    'Probabilities after scaling with 0.1:',\n",
    "    nn.functional.softmax(0.1 * logits, dim=1).numpy()[0]\n",
    ")"
   ],
   "id": "81ff0955d38a1959",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling: [0.10650698 0.10650698 0.78698605]\n",
      "Probabilities after scaling with 0.5: [0.21194156 0.21194156 0.57611686]\n",
      "Probabilities after scaling with 0.1: [0.3104238  0.3104238  0.37915248]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:50:18.508954Z",
     "start_time": "2024-07-28T10:50:17.582723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1)\n",
    "# Less randomness\n",
    "print(sample(model, starting_str='The island', scale_factor=2.0))"
   ],
   "id": "d8ab25f1c4421deb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was arrived to be thing an iron under the sea. A clowed some had been employing out on the sailor, to the world. The stone of the store of the island of the conservicts of the water. It is that a morned to as the bottom of the engineer. “I as not be all the intelligent of the water of the works. The wood, might on\n",
      "the wind on the words on the engineer. The wind the reporter of the sailor of the water of the restion of the other the reporter work of the colonists were leave the doubtle was compl\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T10:51:18.449723Z",
     "start_time": "2024-07-28T10:51:17.539506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1)\n",
    "# More randomness\n",
    "print(sample(model, starting_str='The island', scale_factor=0.5))"
   ],
   "id": "f8fa22aee6e802dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island-\n",
      "pztid\n",
      "bobert, muttel!” an iron umped azoit wick alsoo of awahwic; C7remst pigrelping nevamsyy in,”ro1 hee.\n",
      "His paikely! But juss; t miy?”\n",
      " oon’s return him Sybfan’s’ muss-pile\n",
      "to hais; in-underatior exofo’s on\n",
      "Top!” ago was deed-in hrucky rasns, Jayring!? Theo/, Mr.. Tho,\n",
      "knewnown” oughion has. Tou; Po0ctmoduc ”ill lin\n",
      "Creek o’clows from onefez ocpospairpielied.l\n",
      "sLod hiote’s prittawb,, wevedoesce? 1 vie,\n",
      "togetiomer.\n",
      "instow!” with. 6\n",
      "5e overowled!\n",
      "Non.\n",
      "\n",
      "Af! busififa?\n",
      "Win?”\n",
      "\n",
      "“That is. Towmom.” \n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1099bf3d52796357"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
